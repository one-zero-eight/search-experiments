{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PodYapolsky\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\search-experiments-AGuved54-py3.11\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import util, SentenceTransformer\n",
    "from langchain_text_splitters import (\n",
    "    TextSplitter,\n",
    "    # RecursiveCharacterTextSplitter,\n",
    "    SentenceTransformersTokenTextSplitter,\n",
    ")\n",
    "\n",
    "import torch\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "###########\n",
    "# SOURCES #\n",
    "###########\n",
    "class Source(BaseModel):\n",
    "    id: str\n",
    "    url: str\n",
    "    name: str\n",
    "    desc: str\n",
    "    type: Literal[\"moodle\", \"file\", \"web\", \"tg\"] = Field(\"file\")\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return self.id.__hash__()\n",
    "\n",
    "\n",
    "class MoodleSource(Source):\n",
    "    course_id: str\n",
    "    course_url: str\n",
    "    course_name: str\n",
    "    type: Literal[\"moodle\"] = Field(\"moodle\")\n",
    "\n",
    "\n",
    "class FileSource(Source):\n",
    "    type: Literal[\"file\"] = Field(\"file\")\n",
    "\n",
    "\n",
    "class WebSource(Source):\n",
    "    type: Literal[\"web\"] = Field(\"web\")\n",
    "\n",
    "\n",
    "class TelegramSource(Source):\n",
    "    type: Literal[\"tg\"] = Field(\"tg\")\n",
    "\n",
    "\n",
    "#########\n",
    "# UTILS #\n",
    "#########\n",
    "class Chunk(BaseModel):\n",
    "    index: int = Field(ge=0)\n",
    "    source_id: str\n",
    "    text: str\n",
    "\n",
    "\n",
    "##########\n",
    "# SEARCH #\n",
    "##########\n",
    "class SearchQuery(BaseModel):\n",
    "    text: str\n",
    "\n",
    "\n",
    "class SearchResult(BaseModel):\n",
    "    source: Source\n",
    "    distance: float\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return self.source.id.__hash__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# meta datas\n",
    "DATA_PATH = Path(\"../data\")\n",
    "META_FILE_PATH = DATA_PATH / \"meta.json\"\n",
    "\n",
    "# text data\n",
    "TEXTS_PATH = Path(\"../texts\")\n",
    "PREPROCESSED_PATH = Path(\"../preprocessed\")\n",
    "\n",
    "# all related to validation\n",
    "VALIDATION_PATH = Path(\"../validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sources_info(meta_file_path: Path) -> dict[str, Source]:\n",
    "    with open(meta_file_path, \"r\", encoding=\"utf-8\") as meta_file:\n",
    "        meta_data = json.load(meta_file)\n",
    "\n",
    "    sources_info: dict[str, Source] = {}\n",
    "    for data in meta_data:\n",
    "        source: Source = Source.model_validate_json(json.dumps(data), strict=True)\n",
    "        sources_info[source.id] = source\n",
    "\n",
    "    return sources_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunks_info(meta_file_path: Path, texts_path: Path, text_splitter: TextSplitter) -> dict[int, Chunk]:\n",
    "    # log missing files\n",
    "    logging.basicConfig(\n",
    "        filename=\"missing.log\",\n",
    "        filemode=\"w\",\n",
    "        level=logging.INFO,\n",
    "        encoding=\"utf-8\",\n",
    "    )\n",
    "\n",
    "    with open(meta_file_path, \"r\", encoding=\"utf-8\") as meta_file:\n",
    "        meta_data = json.load(meta_file)\n",
    "\n",
    "    # get current available sources list\n",
    "    sources: list[Source] = []\n",
    "    for data in meta_data:\n",
    "        source: Source = Source.model_validate_json(json.dumps(data), strict=True)\n",
    "        sources.append(source)\n",
    "\n",
    "    index = 0\n",
    "    chunks_info: dict[int, Chunk] = {}\n",
    "    for source in tqdm(sources, total=len(sources), desc=\"Split sources on chunks\", unit=\"source\"):\n",
    "        source_text_path = texts_path / (source.name + \".txt\")\n",
    "\n",
    "        # save not found files into logs\n",
    "        if not os.path.exists(source_text_path):\n",
    "            logging.info(source.id)\n",
    "            continue\n",
    "\n",
    "        # otherwise get their content\n",
    "        with open(source_text_path, \"r\", encoding=\"utf-8\") as text_file:\n",
    "            text = text_file.read()\n",
    "\n",
    "        # update info dict with current source's chunks\n",
    "        for chunk_text in text_splitter.split_text(text):\n",
    "            chunk = Chunk(index=index, source_id=source.id, text=chunk_text)\n",
    "            chunks_info[index] = chunk\n",
    "            index += 1\n",
    "\n",
    "    return chunks_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_by_chunk(chunk_index: int, chunks_info: dict[int, Chunk], sources_info: dict[str, Source]) -> Source:\n",
    "    if not chunks_info.get(chunk_index):\n",
    "        raise ValueError(f\"Chunk {chunk_index} not found\")\n",
    "\n",
    "    chunk: Chunk = chunks_info[chunk_index]\n",
    "\n",
    "    if not sources_info.get(chunk.source_id):\n",
    "        raise ValueError(f\"Source {chunk.source_id} not found\")\n",
    "\n",
    "    return sources_info[chunk.source_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(\n",
    "    texts: list[str],\n",
    "    model: SentenceTransformer,\n",
    ") -> np.ndarray:\n",
    "    embeddings: np.ndarray = model.encode(texts, batch_size=64)  # show_progress_bar=False\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(\n",
    "    query_embedding: np.ndarray,\n",
    "    embeddings: np.ndarray,\n",
    "    sources_info: dict[str, Source],\n",
    "    chunks_info: dict[int, Chunk],\n",
    "    strategy: Literal[\"base\", \"majority_vote\"] = \"base\",\n",
    "    threshold: float = 0.4,\n",
    "    k: int = 10,\n",
    ") -> list[SearchResult]:\n",
    "    \"\"\"Outputs results of semantic search with reranking strategy used among given sources.\n",
    "\n",
    "    Args:\n",
    "        query_embedding (np.ndarray): vector representation of the query of size (1, {embedding_size}).\n",
    "        embeddings (np.ndarray): vector representations of a corpus.\n",
    "        chunks (list[Chunk]): little pieces of sources.\n",
    "        strategy (Literal[\"base\", \"majority_vote\"], optional): reranking strategy among found sources. Defaults to \"base\".\n",
    "        threshold (float, optional): min value of similarity to be present on candidate. Defaults to 0.4.\n",
    "        k (int, optional): final maximum number of sources. Defaults to 10.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: signal that mentioned reranking strategy does not exist.\n",
    "\n",
    "    Returns:\n",
    "        list[SearchResult]: final output of sources.\n",
    "    \"\"\"\n",
    "    results = util.semantic_search(query_embedding, embeddings, top_k=50, score_function=util.dot_score)\n",
    "    assert len(results) == 1\n",
    "\n",
    "    search_results: list[SearchResult] = []\n",
    "    for result in results[0]:\n",
    "        chunk_index = result[\"corpus_id\"]\n",
    "        source: Source = get_source_by_chunk(chunk_index, chunks_info, sources_info)\n",
    "        search_result = SearchResult(text=\"\", source=source, distance=result[\"score\"])\n",
    "        search_results.append(search_result)\n",
    "\n",
    "    # by distance\n",
    "    new_results: list[SearchResult] = []\n",
    "    if strategy == \"base\":\n",
    "        added_source_ids = set()\n",
    "        for search_result in search_results:\n",
    "            if search_result.distance < threshold:  # skip if lower than threshold\n",
    "                continue\n",
    "\n",
    "            if search_result.source.id not in added_source_ids:\n",
    "                added_source_ids.add(search_result.source.id)\n",
    "                new_results.append(search_result)\n",
    "\n",
    "    # count appearance of chunk's belonging to a source\n",
    "    elif strategy == \"majority_vote\":\n",
    "        # apply majority vote\n",
    "        counter = Counter(\n",
    "            [search_result.source for search_result in search_results if search_result.distance > threshold]\n",
    "        )\n",
    "        most_common = counter.most_common(10)\n",
    "\n",
    "        # filter and leave unique documents (a bit of crutch O(n^2))\n",
    "        for source, _ in most_common:\n",
    "            for result in search_results:\n",
    "                if source.id == result.source.id:\n",
    "                    new_results.append(result)\n",
    "                    break\n",
    "    else:\n",
    "        raise ValueError(\"Strategy is not supported\")\n",
    "\n",
    "    return new_results[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_text_file(texts_path: Path, source_name: str):\n",
    "    source_path = texts_path / (source_name + \".txt\")\n",
    "    if not os.path.exists(source_path):\n",
    "        print(f\"File {source_path} not found\")\n",
    "        return\n",
    "\n",
    "    with open(source_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        print(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Split sources on chunks: 100%|██████████| 949/949 [01:29<00:00, 10.64source/s] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a9813929024b319a9ea7b80c2c25bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1470 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PodYapolsky\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\search-experiments-AGuved54-py3.11\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(47011, 384)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain_text_splitters import TextSplitter, RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "# separators = RecursiveCharacterTextSplitter.get_separators_for_language(Language.MARKDOWN) + \\\n",
    "#              RecursiveCharacterTextSplitter.get_separators_for_language(Language.HTML)\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     chunk_size=5000,\n",
    "#     chunk_overlap=500,\n",
    "#     len\n",
    "#     add_start_index=True,\n",
    "#     separators=separators\n",
    "# )\n",
    "\n",
    "# sources info\n",
    "sources_info = load_sources_info(META_FILE_PATH)  # type: ignore\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# model\n",
    "# MODEL_NAME = 'all-mpnet-base-v2'  # SOTA\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(MODEL_NAME, device=device)\n",
    "\n",
    "# split on chunks\n",
    "text_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=50, model_name=MODEL_NAME)\n",
    "# chunks = chunk(text_splitter)\n",
    "chunks_info = load_chunks_info(META_FILE_PATH, TEXTS_PATH, text_splitter)\n",
    "\n",
    "# embed text chunks\n",
    "texts = [chunk.text for chunk in chunks_info.values()]\n",
    "embeddings = embed(texts, model)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac54dcfacf0b420fb123e796b1bbfc60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[SearchResult(source=Source(id='module-78518.pdf', url='https://moodle.innopolis.university/mod/resource/view.php?id=78518', name='module-78518.pdf', desc='Lab 4 (bul)', type='moodle'), distance=0.48109304904937744),\n",
       " SearchResult(source=Source(id='module-79154.pdf', url='https://moodle.innopolis.university/mod/resource/view.php?id=79154', name='module-79154.pdf', desc='Graph Theory (main book)', type='moodle'), distance=0.4612114131450653),\n",
       " SearchResult(source=Source(id='https://innopolis.university/upload/iblock/0b3/92tmskeuzgrgqcs5r64xlb1g8g9i4tf7/Отчет_о_результатах_самообследования__2024__на_сайт.pdf', url='https://innopolis.university/upload/iblock/0b3/92tmskeuzgrgqcs5r64xlb1g8g9i4tf7/Отчет_о_результатах_самообследования__2024__на_сайт.pdf', name='Отчет_о_результатах_самообследования__2024__на_сайт.pdf', desc='Отчет о результатах самообследования Автономной некоммерческой организацией высшего образования «Университет Иннополис» за 2023 год', type='file'), distance=0.44731366634368896),\n",
       " SearchResult(source=Source(id='module-108403.pdf', url='https://moodle.innopolis.university/mod/resource/view.php?id=108403', name='module-108403.pdf', desc='Lecture Week 2 Part I (Network Characteristics)', type='moodle'), distance=0.4472094476222992),\n",
       " SearchResult(source=Source(id='module-83884.pdf', url='https://moodle.innopolis.university/mod/resource/view.php?id=83884', name='module-83884.pdf', desc='Tutorial 7 Slides', type='moodle'), distance=0.4386726915836334),\n",
       " SearchResult(source=Source(id='module-89991.pdf', url='https://moodle.innopolis.university/mod/resource/view.php?id=89991', name='module-89991.pdf', desc='Week 2. Problem set (solutions)', type='moodle'), distance=0.428679883480072),\n",
       " SearchResult(source=Source(id='module-89469.pdf', url='https://moodle.innopolis.university/mod/resource/view.php?id=89469', name='module-89469.pdf', desc='Numerical Linear Algebra', type='moodle'), distance=0.4234936535358429),\n",
       " SearchResult(source=Source(id='module-92978.pdf', url='https://moodle.innopolis.university/mod/resource/view.php?id=92978', name='module-92978.pdf', desc='Lecture 14. Flow networks. Ford-Fulkerson. Max flow min cut', type='moodle'), distance=0.41140374541282654),\n",
       " SearchResult(source=Source(id='module-89466.pdf', url='https://moodle.innopolis.university/mod/resource/view.php?id=89466', name='module-89466.pdf', desc='Linear Algebra and Its Applications', type='moodle'), distance=0.40359067916870117)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = SearchQuery(text=\"Burmykov Networks course lecture 11\")\n",
    "query_embedding = embed([query.text], model)\n",
    "\n",
    "results: list[SearchResult] = search(\n",
    "    query_embedding, embeddings, sources_info, chunks_info, strategy=\"base\", threshold=0.4, k=10\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a2f93624444d0794149f182f920a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[SearchResult(source=Source(id='module-92034.pdf', url='https://moodle.innopolis.university/mod/resource/view.php?id=92034', name='module-92034.pdf', desc='Tutorial 08 - SOLID', type='moodle'), distance=0.46830806136131287),\n",
       " SearchResult(source=Source(id='module-92216.pdf', url='https://moodle.innopolis.university/mod/resource/view.php?id=92216', name='module-92216.pdf', desc='2023 SSAD 14 Command, Chain or Resp, SOLID', type='moodle'), distance=0.4331497550010681)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = SearchQuery(text=\"SOLID principles examples\")\n",
    "query_embedding = embed([query.text], model)\n",
    "\n",
    "results: list[SearchResult] = search(\n",
    "    query_embedding,\n",
    "    embeddings,\n",
    "    sources_info,\n",
    "    chunks_info,\n",
    "    strategy=\"base\",  # base\n",
    "    threshold=0.4,\n",
    "    k=10,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b656e039ed1d45de8620b3ac979618ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = SearchQuery(text=\"aboba sus amogus\")\n",
    "query_embedding = embed([query.text], model)\n",
    "\n",
    "results: list[SearchResult] = search(\n",
    "    query_embedding, embeddings, sources_info, chunks_info, strategy=\"base\", threshold=0.4, k=10\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestQuery(BaseModel):\n",
    "    text: str\n",
    "    relevant: bool\n",
    "    sources: list[str] | None\n",
    "\n",
    "\n",
    "def load_test_queries(validation_path: Path) -> list[TestQuery]:\n",
    "    queries: list[TestQuery] = []\n",
    "    with open(validation_path / \"queries.jsonl\", \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            query = TestQuery.model_validate_json(line, strict=True)\n",
    "            if query.relevant:\n",
    "                queries.append(query)\n",
    "\n",
    "    return queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestQuery(text='verilog syntax', relevant=True, sources=['module-84616.pdf', 'module-84621.pdf', 'module-84787.pdf'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = load_test_queries(VALIDATION_PATH)\n",
    "\n",
    "queries[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f61af92a4e4cb1971b2a6021290759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ranx import Qrels, Run, evaluate\n",
    "\n",
    "qrels = Qrels(name=\"queries\")\n",
    "run = Run(name=\"queries\")\n",
    "\n",
    "test_query_embedding = embed([query.text for query in queries], model)\n",
    "for i, query in enumerate(queries):  # [49:51]\n",
    "    results: list[SearchResult] = search(\n",
    "        test_query_embedding[i].reshape(1, -1),\n",
    "        embeddings,\n",
    "        sources_info,\n",
    "        chunks_info,\n",
    "        strategy=\"base\",\n",
    "        threshold=0.4,\n",
    "        k=10,\n",
    "    )\n",
    "\n",
    "    qrels.add(q_id=query.text, doc_ids=query.sources, scores=[i for i in range(len(query.sources), 0, -1)])\n",
    "\n",
    "    result_ids = [result.source.id for result in results]\n",
    "    if len(result_ids) == 0:\n",
    "        result_ids = [\"test\"]\n",
    "    run.add(q_id=query.text, doc_ids=result_ids, scores=[i for i in range(len(result_ids), 0, -1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10     : 0.88\n",
      "hit_rate@10 : 0.62\n",
      "recall@10   : 0.52\n",
      "precision@10: 0.09\n",
      "map@10      : 0.34\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate(qrels, run, [\"hits@10\", \"hit_rate@10\", \"recall@10\", \"precision@10\", \"map@10\"])\n",
    "\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k:<12}: {v:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search-experiments-AGuved54-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
